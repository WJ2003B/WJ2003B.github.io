<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Bill Zheng</title>

    <meta name="author" content="Bill Zheng">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/seal.svg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="style.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Bill Zheng
                </p>
                <p>I'm a fourth-year undergraduate student at UC Berkeley studying Electrical Engineering and Computer Science</a>.
                </p>
                <p>
                  I am grateful to be advised by Professor <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> at <a href="https://rail.eecs.berkeley.edu/">Robotics, AI, and Learning Lab</a>. I am also fortunate to work with Professor <a href="https://kuanfang.github.io/">Kuan Fang</a> and Professor <a href="https://ben-eysenbach.github.io/">Benjamin Eysenbach</a>  as well. I'm broadly interested in the intersection between machine learning and robotics, focusing on the idea of <i>horizon generalization</i> in real-world robot learning problems via the use of reinforcement learning.
                </p>

                <p><b>I am applying to PhD programs for Fall 2026! I'm also looking for internship opportunities for Summer 2026.</b></p>
                <p style="text-align:center">
                  <a href="mailto:bill.cy.zheng@berkeley.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=N0tYevAAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/BillZheng155508">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/WJ2003B/">Github</a> &nbsp;/&nbsp;
                  <a href="./cv.pdf">cv</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.png"></a>
              </td>
            </tr>
          </tbody></table>
          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <h2>Research</h2>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <p>
                  My research interests have been driven by the idea of <i>horizon generalization</i>. If we want autonomous agents to learn complex tasks that are composed of simpler tasks seen in the training set, we need to design our policies such that we can achieve this "stitching" behavior without explicit planning. I believe this to be a representation learning problem, and I am interesting in seeing how can we use effective representations in policy learning to solve this problem.
                </p>
              </td>
            </tr>
          </tbody></table> -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
            <h2>News</h2>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <br>
              [Dec. 2025] I will be attending <i>NeurIPS</i> in San Diego!
              <br>
              [Nov. 2025] I will be attending <i>Choose Good Quests</i> in San Francisco. Looking for exciting topics to work on for robot learning!
              <br>
              [Sep. 2025] TRA and TMD have been accepted by NeurIPS 2025! See you in San Diego!
	            </p>
            </td>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
              <h2>Selected Publications</h2>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                 
                  <div class="one">
      
                    <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
                      <source src="images/nuvo.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                      </video></div>
                      <img src='images/mainfig_mqe.svg' width=100%></div>
                  </div>
                  <script type="text/javascript">
                    function nuvo_start() {
                      document.getElementById('nuvo_image').style.opacity = "1";
                    }
          
                    function nuvo_stop() {
                      document.getElementById('nuvo_image').style.opacity = "0";
                    }
                    nuvo_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://mqe-paper.github.io/">
                    <span class="papertitle">Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning</span>
                  </a>
                  <br>
                  <strong>Bill Zheng</strong>,
                  <a href="https://people.eecs.berkeley.edu/~vmyers/">Vivek Myers</a>,
                  <a href="https://ben-eysenbach.github.io/">Benjamin Eysenbach</a>,
                  <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                  <br>
                  <em>Preprint</em>
                  <br>
                  <a href="https://arxiv.org/pdf/2511.07730">paper</a> /
                  <a href="https://mqe-paper.github.io">website</a> / 
                  <!-- <a href="https://github.com/vivekmyers/tmd-release/">code</a> / -->
                  <!-- <a href="https://arxiv.org/abs/2509.20478">arXiv</a> -->
                  <p></p>
                  <p>
                  We demonstrate the effectiveness of using quasimetric distance representations in horizon-generalization by performing multistep backups. This allows us to scale up compositional tasks to real-world, pixel-based tasks using offline GCRL. 
                  </p>
                </td>
                </tr>
              <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
               
                <div class="one">
    
                  <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
                  <source src="https://res.cloudinary.com/dp7qzzmt2/video/upload/v1752709113/tmd-anim_bn0p88.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <video  width=100% muted autoplay loop>
                    <source src="https://res.cloudinary.com/dp7qzzmt2/video/upload/v1752709113/tmd-anim_bn0p88.mp4" type="video/mp4">
                  </video>
                </div>
                <script type="text/javascript">
                  function nuvo_start() {
                    document.getElementById('nuvo_image').style.opacity = "1";
                  }
        
                  function nuvo_stop() {
                    document.getElementById('nuvo_image').style.opacity = "0";
                  }
                  nuvo_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://tmd-website.github.io/">
                  <span class="papertitle">Offline Goal-Conditioned Reinforcement Learning with Quasimetric Representations</span>
                </a>
                <br>
                <a href="https://people.eecs.berkeley.edu/~vmyers/">Vivek Myers</a>,
                <strong>Bill Zheng</strong>,
                <a href="https://ben-eysenbach.github.io/">Benjamin Eysenbach</a>,
                <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                <br>
                <em>NeurIPS</em> 2025
                <br>
                <a href="https://tmd-website.github.io/static/pdf/tmd.pdf">paper</a> /
                <a href="https://tmd-website.github.io">website</a> / 
                <a href="https://github.com/vivekmyers/tmd-release/">code</a> /
                <a href="https://arxiv.org/abs/2509.20478">arXiv</a>
                <p></p>
                <p>
                Using a combination of Monte-Carlo contrastive learning and necessary invariances, we can find the optimal goal-reaching Q function with quasimetric representations in offline goal-conditioned reinforcement learning (GCRL).
                </p>
              </td>
              </tr>
              <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
               
                <div class="one">
    
                  <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
                  <source src="images/tra.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/demo2.png' width=100%>
                </div>
                <script type="text/javascript">
                  function nuvo_start() {
                    document.getElementById('nuvo_image').style.opacity = "1";
                  }
        
                  function nuvo_stop() {
                    document.getElementById('nuvo_image').style.opacity = "0";
                  }
                  nuvo_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://tra-paper.github.io/">
                  <span class="papertitle">Temporal Representation Alignment: Successor Features Enable Emergent Compositionality in Robot Instruction Following</span>
                </a>
                <br>
                <a href="https://people.eecs.berkeley.edu/~vmyers/">Vivek Myers*</a>,
                <strong>Bill Zheng*</strong>,
                <a href="https://people.eecs.berkeley.edu/~anca/">Anca Dragan</a>,
                <a href="https://kuanfang.github.io/">Kuan Fang</a>,
                <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                <br>
		<em>NeurIPS</em> 2025
		<br>
                <em>Learning Efficient Abstractions for Planning Workshop, CoRL</em> 2024
                <br>
                <a href="https://tra-paper.github.io/static/pdf/tra.pdf">paper</a> /
                <a href="https://tra-paper.github.io">website</a> / 
                <a href="https://anonymous.4open.science/r/ogcrl-43A4/README.md">code</a> /
                <a href="https://arxiv.org/abs/2502.05454">arXiv</a>
                <p></p>
                <p>
                We propose Temporal Representation Alignment (TRA), a policy learning method that utilizes the quasimetric property of temporal distances, and observe emergent capabilities in following compositional instructions when trained on a real world robot dataset.
                </p>
              </td>
            </tr>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/output.gif' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://palo-website.github.io">
          <span class="papertitle">Policy Adaptation via Language Optimization: Decomposing Tasks for Few-Shot Imitation</span>
        </a>
        <br>
        <a href="https://people.eecs.berkeley.edu/~vmyers/">Vivek Myers*</a>,
        <strong>Bill Zheng*</strong>,
        <a href="https://www.oiermees.com/">Oier Mees</a>,
		<a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine&dagger;</a>,
        <a href="https://kuanfang.github.io/">Kuan Fang&dagger;</a>
        <br>
        <em>CoRL</em> 2024
        <br>
	<a href="https://palo-website.github.io">project page</a>
	/
        <a href="https://x.com/vivek_myers/status/1834785002116255832">twitter</a>
        /
        <a href="https://github.com/vivekmyers/palo">code</a>
        /
        <a href="https://arxiv.org/pdf/2408.16228">arXiv</a>
        <p>We propose an effective and sample-efficient nonparametric adaptation method for learning new language-conditioned robotic manipulation tasks by searching for the best language decomposition and executing these instructions in inference.</p>
        <p>
        
        </p>
      </td>
    </tr>
    </tbody>
    </table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <h2>Teaching & Volunteering</h2>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td width="50%" style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/eecs.png" alt="cs180" width="160" height="160">
              </td>
              <td width="75%" valign="center">
		<a href="https://people.eecs.berkeley.edu/~jrs/189/">Undergraduate Student Instructor, CS189/289A (Introduction to Machine Learning), Spring 2025</a>
                <br>
                <a href="https://inst.eecs.berkeley.edu/~cs180/fa24/">Tutor, CS180/280A (Introduction to Computer Vision), Fall 2024</a>
                <br>
                <a href="https://rdi.berkeley.edu/responsible-genai/f23">Reader, CS194-196/294-196 (Responsible Generative AI), Fall 2023</a>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody></tbody>
            <tr>
              <td width="50%" style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/csm.png" alt="csm" width="160" height="160">
              </td>
              <td width="75%" valign="center">
                <a href="https://csmentors.studentorg.berkeley.edu/#/">Course Coordinator, EECS16B (Designing Information Devices and Systems II), Computer Science Mentors</a>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody></tbody>
            <tr>
              <td>
                <h2>Miscellaneous</h2>
                <p>I grew up in Orange County, California, so my collection of favorite sports teams are peculiar (Go Warriors, 49ers, Angels, and Ducks!). In my (somewhat) free time, I like to enjoy the following:</p>
            <ul>
              <li>Classical music (My favorite composers are Sergei Rachmaninoff, Richard Strauss, and Dmitri Shostakovich).</li>
              <li>Sports analytics. <a href="https://www.youtube.com/thinkingbasketball">Thinking Basketball</a> and <a href="https://www.youtube.com/@michaelmackelvie">Michael MacKelvie</a> on YouTube are good introductions if you want to get to know more about NBA and NFL analytics.</li>
              <li>Playing Civilization (5 and 6).</li>
              <li>Weightlifting.</li>
              <li>Pedagogy.</li>
              <li>Cooking (mostly grilling).</li>
            </ul>
              </td>
            </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template used from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
